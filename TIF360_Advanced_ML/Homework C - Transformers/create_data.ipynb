{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jespe\\anaconda3\\envs\\HW_C_env\\lib\\site-packages\\deeptrack\\backend\\_config.py:11: UserWarning: cupy not installed. GPU-accelerated simulations will not be possible\n",
      "  warnings.warn(\n",
      "c:\\Users\\jespe\\anaconda3\\envs\\HW_C_env\\lib\\site-packages\\deeptrack\\backend\\_config.py:25: UserWarning: cupy not installed, CPU acceleration not enabled\n",
      "  warnings.warn(\"cupy not installed, CPU acceleration not enabled\")\n",
      "c:\\Users\\jespe\\anaconda3\\envs\\HW_C_env\\lib\\site-packages\\tensorflow_addons\\utils\\tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\jespe\\anaconda3\\envs\\HW_C_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import deeptrack as dt\n",
    "import numpy as np\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "sequence_length = 10  # Number of frames per sequence\n",
    "MIN_SIZE = 0.5e-6\n",
    "MAX_SIZE = 1.5e-6\n",
    "MAX_VEL = 10  # Maximum velocity. The higher the trickier!\n",
    "MAX_PARTICLES = 3  # Max number of particles in each sequence. The higher the trickier!\n",
    "\n",
    "# Defining properties of the particles\n",
    "particle = dt.Sphere(\n",
    "    intensity=lambda: 10 + 10 * np.random.rand(),\n",
    "    radius=lambda: MIN_SIZE + np.random.rand() * (MAX_SIZE - MIN_SIZE),\n",
    "    position=lambda: IMAGE_SIZE * np.random.rand(2),\n",
    "    vel=lambda: MAX_VEL * np.random.rand(2),\n",
    "    position_unit=\"pixel\",\n",
    ")\n",
    "\n",
    "# Defining an update rule for the particle position\n",
    "def get_position(previous_value, vel):\n",
    "\n",
    "    newv = previous_value + vel\n",
    "    for i in range(2):\n",
    "        if newv[i] > 63:\n",
    "            newv[i] = 63 - np.abs(newv[i] - 63)\n",
    "            vel[i] = -vel[i]\n",
    "        elif newv[i] < 0:\n",
    "            newv[i] = np.abs(newv[i])\n",
    "            vel[i] = -vel[i]\n",
    "    return newv\n",
    "\n",
    "\n",
    "particle = dt.Sequential(particle, position=get_position)\n",
    "\n",
    "# Defining properties of the microscope\n",
    "optics = dt.Fluorescence(\n",
    "    NA=1,\n",
    "    output_region=(0, 0, IMAGE_SIZE, IMAGE_SIZE),\n",
    "    magnification=10,\n",
    "    resolution=(1e-6, 1e-6, 1e-6),\n",
    "    wavelength=633e-9,\n",
    ")\n",
    "\n",
    "# Combining everything into a dataset.\n",
    "# Note that the sequences are flipped in different directions, so that each unique sequence defines\n",
    "# in fact 8 sequences flipped in different directions, to speed up data generation\n",
    "sequential_images = dt.Sequence(\n",
    "    optics(particle ** (lambda: 1 + np.random.randint(MAX_PARTICLES))),\n",
    "    sequence_length=sequence_length,\n",
    ")\n",
    "dataset = sequential_images >> dt.FlipUD() >> dt.FlipDiagonal() >> dt.FlipLR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(2e4)\n",
    "val_len = int(2e3)\n",
    "\n",
    "train_pictures = []\n",
    "for i in range(train_len):\n",
    "    train_pictures.extend(dataset.update().resolve())\n",
    "train_pictures = np.array(train_pictures).reshape(train_len, 10, 64, 64, 1) \n",
    "np.save('train_pictures_20k.npy', train_pictures)\n",
    "\n",
    "val_pictures = []\n",
    "for i in range(val_len):\n",
    "    val_pictures.extend(dataset.update().resolve())\n",
    "val_pictures = np.array(val_pictures).reshape(val_len, 10, 64, 64, 1)\n",
    "np.save('val_pictures_2k.npy', val_pictures)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HW_C_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
